{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "name": "shallow-tensorflow.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/CSC645/blob/master/shallow_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_9a9QfU6tyE",
        "colab_type": "text"
      },
      "source": [
        "## Using Tensorflow to model the shallow network\n",
        "In this exercise will we redo, using tensorflow the shallow network that we trained from first\n",
        "principles before to recognize the \"flower\" shape.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o5vlX9u6tyJ",
        "colab_type": "text"
      },
      "source": [
        "### Reading the data\n",
        "First recall that tensorflow stacks the samples row-wise instead of column-wise\n",
        "as we have been doing when we did the gradient descent oursleves. Therefore in the last line of the\n",
        "function load_dataset() below we don't take the transpose of X and Y as we did before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6LCDtOS6tyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def load_dataset(n):\n",
        "    np.random.seed(1)\n",
        "    m = n # number of examples\n",
        "    N = int(m/2) # number of points per class\n",
        "    D = 2 # dimensionality\n",
        "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
        "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
        "    a = 4 # maximum ray of the flower\n",
        "\n",
        "    for j in range(2):\n",
        "        ix = range(N*j,N*(j+1))\n",
        "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
        "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
        "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
        "        Y[ix] = j\n",
        "\n",
        "    return X, Y\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teN_wh7f6tyc",
        "colab_type": "text"
      },
      "source": [
        "### Defining the parameters\n",
        "Below we define the parameters that are needed. We know that n_x=2 and n_y=1 but we extract them from the shape of\n",
        "X_data and Y_data after we call load_dataset() . We also set the number\n",
        "of data points to 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkvlW8pG6tyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 5\n",
        "nb_iterations = 5000\n",
        "num_data=500 #number of data points\n",
        "X_data,Y_data=load_dataset(num_data)# load data\n",
        "# Network Parameters\n",
        "n_h = 4 # number of neurons in hidden layer\n",
        "n_x = None #number of neurons in input\n",
        "n_y = None #number of neurons in ouput"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQxrSVDO6tyt",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "\n",
        "Since tensorflow stacks the data row-wise the forward propagation is slightly different then we are used to.\n",
        "Let $W^1$,$W^2$,$b^1$,$b^2$ be the weights and biases of the first and second layer respectively then forward propagation is define as\n",
        "\\begin{align*}\n",
        "Z^1&=X\\cdot W^1+b^1\\\\\n",
        "A^1 &=\\sigma(Z^1)\\\\\n",
        "Z^2 &=A^1\\cdot W^2+b2\\\\\n",
        "A^2 &=\\sigma(Z^2)\n",
        "\\end{align*}\n",
        "Accorging to the above equations you have to define the tensorflow variables that will hold the weights and biases. \n",
        "The biases are set to zero using the tensorflow function tf.zeros([size]) and the weights randomly using tf.random_normal([size1,size2]) using the appropriate sizes.\n",
        "Also we have to define two placeholders for the data X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFAGn-Rb6tyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=None #define a placeholder to take the X\n",
        "Y=None #define a placeholer to take the Y\n",
        "W1=None #Weights of the first layer\n",
        "W2=None #weights of the second layer\n",
        "b1=None           #biases of the first layer\n",
        "b2=None           #biases of the second layer\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmeMxCuk6ty_",
        "colab_type": "text"
      },
      "source": [
        "### Defining the model\n",
        "Our model has two layers. The function \"model\" below should return the ouput of our model for a given input.\n",
        "Please refre to the figure above.\n",
        "The dot product of two matrices $A\\cdot B$ is done in tensorflow as tf.matmul(A,B).\n",
        "The sigmoid function is accessible in tensorflow using tf.sigmoid()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIDe-75f6tzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input):\n",
        "    # Hidden fully connected layer with 256 neurons\n",
        "    layer_1 = None\n",
        "    # Output fully connected layer with a neuron for each class\n",
        "    out_layer = None\n",
        "    return out_layer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFv6cmHI6tzR",
        "colab_type": "text"
      },
      "source": [
        "Once the model is defined the remaining code is similar to our previous exercise. We define the loss\n",
        "as an average over the cross-entropy but this time since it is binary classification we use the sigmoid instead\n",
        "of the softmax function. Then our optimizer uses gradient descent to minimize the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orD2CShG6tzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "00eed72d-8406-461d-9794-ea62ee620c39"
      },
      "source": [
        "a = model(X)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=a, labels=Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-68fe22486484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.pyc\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m    237\u001b[0m   \"\"\"\n\u001b[1;32m    238\u001b[0m   return sigmoid_cross_entropy_with_logits(\n\u001b[0;32m--> 239\u001b[0;31m       logits=logits, labels=labels, name=name)\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.pyc\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   nn_ops._ensure_xent_args(\"sigmoid_cross_entropy_with_logits\", _sentinel,\n\u001b[0;32m--> 160\u001b[0;31m                            labels, logits)\n\u001b[0m\u001b[1;32m    161\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36m_ensure_xent_args\u001b[0;34m(name, sentinel, labels, logits)\u001b[0m\n\u001b[1;32m   3102\u001b[0m                      \"named arguments (labels=..., logits=..., ...)\" % name)\n\u001b[1;32m   3103\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3104\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both labels and logits must be provided.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Both labels and logits must be provided."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hTiLC286tzf",
        "colab_type": "text"
      },
      "source": [
        "Now that the model is defined we run our computation in a session. Given a matrix M we compute the transpose\n",
        "in numpy as X.T, in tensorflow we use tf.transpose(M).\n",
        "To compute the prediction we set all values >0.5 to 1 otherwise we set to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhSVGO3Q6tzh",
        "colab_type": "code",
        "colab": {},
        "outputId": "51d2b035-24bf-46af-849a-17d08d094a01"
      },
      "source": [
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    # Training cycle\n",
        "    for i in range(nb_iterations):\n",
        "\n",
        "        _, c = sess.run([optimizer, loss], feed_dict={X: X_data, Y: Y_data})\n",
        "        if i%1000==0:\n",
        "            print(\"loss is %f for step %d\" %(c,i))\n",
        "    #Test model \n",
        "    #Convert your answer in the shallow notebook to tensorflow\n",
        "    #first compute the probabilities\n",
        "    pred=None\n",
        "    #second convert the probabilities  to 1 and 0 using 0.5 as a threshold\n",
        "    pred=None\n",
        "    #third compute all correct answers\n",
        "    pred=None\n",
        "    #finally run pred in a session\n",
        "    res=sess.run(pred,feed_dict={X:X_data,Y:Y_data})\n",
        "    print(\"Accuracy:%f\" %(float(res)/float(num_data)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-24101c018a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initializing the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjxMCmk16tzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}