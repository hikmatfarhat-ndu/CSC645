{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZGzIz+HIlahjQIU0YaB8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/CSC645/blob/master/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaxQ0EUaIFeq"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense,Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential, Model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y1Id3QZ9Cq7",
        "outputId": "58e5adb9-42c5-44ab-e443-e0351193488a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=keras.datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydcVhIiy9hUq",
        "outputId": "cddab4e2-3e8f-4b08-967a-6ed54f549f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "train_x = x_train.reshape(60000, 784) / 255\n",
        "val_x = x_test.reshape(10000, 784) / 255\n",
        "\n",
        "autoencoder = keras.models.Sequential()\n",
        "autoencoder.add(Dense(512,  activation='elu', input_shape=(784,)))\n",
        "autoencoder.add(Dense(128,  activation='elu'))\n",
        "autoencoder.add(Dense(10,    activation='linear', name=\"bottleneck\"))\n",
        "autoencoder.add(Dense(128,  activation='elu'))\n",
        "autoencoder.add(Dense(512,  activation='elu'))\n",
        "autoencoder.add(Dense(784,  activation='sigmoid'))\n",
        "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
        "trained_model = autoencoder.fit(train_x, train_x, batch_size=1024, epochs=10, verbose=1, validation_data=(val_x, val_x))\n",
        "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
        "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
        "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
        "encoding_dim = 10\n",
        "\n",
        "# return the decoder\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "decoder = autoencoder.layers[-3](encoded_input)\n",
        "decoder = autoencoder.layers[-2](decoder)\n",
        "decoder = autoencoder.layers[-1](decoder)\n",
        "decoder = Model(encoded_input, decoder)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "59/59 [==============================] - 6s 108ms/step - loss: 0.0756 - val_loss: 0.0497\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 106ms/step - loss: 0.0430 - val_loss: 0.0372\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 106ms/step - loss: 0.0340 - val_loss: 0.0299\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 106ms/step - loss: 0.0283 - val_loss: 0.0261\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 105ms/step - loss: 0.0256 - val_loss: 0.0241\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 106ms/step - loss: 0.0239 - val_loss: 0.0227\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 106ms/step - loss: 0.0227 - val_loss: 0.0216\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 106ms/step - loss: 0.0216 - val_loss: 0.0207\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 6s 107ms/step - loss: 0.0207 - val_loss: 0.0199\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 6s 107ms/step - loss: 0.0200 - val_loss: 0.0192\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}