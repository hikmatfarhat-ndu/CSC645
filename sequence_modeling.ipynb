{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "sequence-modeling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/CSC645/blob/master/sequence_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13NLGKdqH92v",
        "outputId": "f984272b-e6a1-4a0b-e81f-773e27749119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p64nYl4lH920"
      },
      "source": [
        "# Sequence modelling \n",
        "\n",
        "## Coding tutorials\n",
        " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
        " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
        " #### [3. The Embedding layer](#coding_tutorial_3)\n",
        " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
        " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
        " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfGnxJ_PH921"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR-iKXE4H922"
      },
      "source": [
        "#### Load the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYAlPv_3H922"
      },
      "source": [
        "# Import imdb\n",
        "import tensorflow.keras.datasets.imdb as imdb "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lWf_skeH927",
        "outputId": "42985e6a-8328-4804-b6f4-f5f436cf9798"
      },
      "source": [
        "# Download and assign the data set using load_data()\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QByeFp1-H929"
      },
      "source": [
        "#### Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOKcazZ-H929",
        "outputId": "df11f73e-5426-433d-c1bc-2a2d27884278"
      },
      "source": [
        "# Inspect the type of the data\n",
        "x_train[0][0:10]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAmh7RBPH93A"
      },
      "source": [
        "# Inspect the shape of the data\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M13T9MYmH93D"
      },
      "source": [
        "# Display the first dataset element input\n",
        "# Notice encoding\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vC8tfilH93F"
      },
      "source": [
        "# Display the first dataset element output\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsBkT84WH93H"
      },
      "source": [
        "#### Load dataset with different options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FibusPh6H93I"
      },
      "source": [
        "# Load the dataset with defaults\n",
        "\n",
        "\n",
        "# ~/.keras/dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUqaib9vH93K"
      },
      "source": [
        "# Limit the vocabulary to the top 500 words using num_words\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY0nVpL5H93L"
      },
      "source": [
        "# Ignore the top 10 most frequent words using skip_top\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyJoRvxnH93O"
      },
      "source": [
        "# Limit the sequence lengths to 500 using maxlen\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGl2t4FzH93Q"
      },
      "source": [
        "# Use '1' as the character that indicates the start of a sequence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV5FtNUNH93T"
      },
      "source": [
        "#### Explore the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JPbqBjIH93U"
      },
      "source": [
        "# Load the imdb word index using get_word_index()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjSZn6FxH93W"
      },
      "source": [
        "# View the word index as a dictionary,\n",
        "# accounting for index_from.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pNrOLrHH93Y"
      },
      "source": [
        "# Retrieve a specific word's index\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QHwuY7vH93a"
      },
      "source": [
        "# View an input sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d7zj8y0H93c"
      },
      "source": [
        "# Get the sentiment value\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHVV1zb9H93f"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Padding and Masking Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BCmQvaBH93f"
      },
      "source": [
        "# Load the imdb data set\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkvZ0PIfH93i"
      },
      "source": [
        "#### Preprocess the data with padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCr27NoEH93j"
      },
      "source": [
        "# Inspect the input data shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMX6ScXMH93l"
      },
      "source": [
        "# Pad the inputs to the maximum length using maxlen\n",
        "\n",
        "x_train_pad=tf.keras.preprocessing.sequence.pad_sequences(x_train,maxlen=300,\n",
        "padding='post',truncating='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "213GcrjfH93n",
        "outputId": "4e5ad122-d0a4-4fc0-99d0-ba0957d3670b"
      },
      "source": [
        "# Inspect the output data shape\n",
        "\n",
        "x_train_pad.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDH66f7KH93p"
      },
      "source": [
        "#### Create a Masking layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84PuXe5zH93p"
      },
      "source": [
        "# Import numpy \n",
        "import numpy  as np \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGauvsn1H93s"
      },
      "source": [
        "# Masking expects to see (batch, sequence, features)\n",
        "# Create a dummy feature dimension using expand_dims\n",
        "padded_x_train=np.expand_dims(x_train_pad,-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5HXuT0aH93u"
      },
      "source": [
        "# Create a Masking layer \n",
        "tf_x_train=tf.convert_to_tensor(padded_x_train,dtype='float32')\n",
        "mask_layer=tf.keras.layers.Masking(mask_value=0,)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rekywi0dH93y"
      },
      "source": [
        "# Pass tf_x_train to it\n",
        "masked_x_train=mask_layer(tf_x_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmkU8oOHH931",
        "outputId": "e1ebf3c8-1459-4867-e089-9e06540d8c4d"
      },
      "source": [
        "# Look at the dataset\n",
        "masked_x_train.shape\n",
        "masked_x_train._keras_mask\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=8, shape=(25000, 300), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ORzULiIH933"
      },
      "source": [
        "# Look at the ._keras_mask for the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qcZxQ4SH935"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giGe8bCBH935"
      },
      "source": [
        "#### Create and apply an `Embedding` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKwfU2IcH936"
      },
      "source": [
        "# Create an embedding layer using layers.Embedding\n",
        "# Specify input_dim, output_dim, input_length\n",
        "\n",
        "embedding_layer=tf.keras.layers.Embedding(input_dim=501,output_dim=16)\n",
        "#expects input of the shape\n",
        "# (batch,sequence,features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgA8jGwcH938",
        "outputId": "946d7074-aeab-4812-a62c-ebcb0e832a8a"
      },
      "source": [
        "# Inspect an Embedding layer output for a fixed input\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "sequence=tf.constant([[[0],[1],[5],[500]]])\n",
        "sequence_of_embeddings=embedding_layer(sequence)\n",
        "sequence_of_embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=50, shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
              "array([[[[-4.93819825e-02,  4.79670279e-02, -4.96466421e-02,\n",
              "           3.59516218e-03, -3.58911380e-02,  1.40239261e-02,\n",
              "           4.77942564e-02,  2.30529942e-02, -3.26102003e-02,\n",
              "           1.12731382e-03,  2.42405646e-02, -3.24548483e-02,\n",
              "          -2.46376917e-03, -4.54859845e-02,  1.20875835e-02,\n",
              "          -1.46036223e-03]],\n",
              "\n",
              "        [[ 3.30866463e-02, -8.53872299e-03, -4.86984104e-03,\n",
              "           5.25255129e-03, -2.87134647e-02,  3.80150191e-02,\n",
              "           8.71196389e-05, -3.77577431e-02,  6.29421324e-03,\n",
              "           3.86125706e-02, -4.43064235e-02,  2.27995031e-02,\n",
              "          -1.58297531e-02, -4.99626286e-02,  1.49161108e-02,\n",
              "          -1.66587718e-02]],\n",
              "\n",
              "        [[-3.72087471e-02, -8.19934532e-03, -5.69223240e-03,\n",
              "           1.29581355e-02,  4.24976610e-02, -2.05596928e-02,\n",
              "          -2.67336722e-02,  4.31881100e-03, -2.25387458e-02,\n",
              "          -1.73893347e-02, -2.31876615e-02,  4.91886251e-02,\n",
              "           3.83999683e-02,  3.60265113e-02, -1.89701915e-02,\n",
              "          -4.96377349e-02]],\n",
              "\n",
              "        [[-9.31658596e-03, -1.54412985e-02,  2.82654651e-02,\n",
              "           4.44219448e-02, -2.31865998e-02,  3.99441235e-02,\n",
              "           2.57577784e-02, -2.41451152e-02, -1.37009993e-02,\n",
              "           1.38963498e-02,  2.85608061e-02,  4.14073132e-02,\n",
              "           3.07329781e-02, -1.83495991e-02,  4.91590835e-02,\n",
              "          -4.22675386e-02]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAlsPukyH93_",
        "outputId": "833ccaba-f4eb-4a29-f082-c59a1f91503c"
      },
      "source": [
        "# Inspect the Embedding layer weights using get_weights()\n",
        "# in this case it returns a list of just one element\n",
        "w=embedding_layer.get_weights()\n",
        "w[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(501, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8xX0jEwH94A",
        "outputId": "84505f90-9e6f-4185-ea39-ca79394eb8ae"
      },
      "source": [
        "# Get the embedding for the 14th index\n",
        "embedding_layer.get_weights()[0][0,:]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04938198,  0.04796703, -0.04964664,  0.00359516, -0.03589114,\n",
              "        0.01402393,  0.04779426,  0.02305299, -0.0326102 ,  0.00112731,\n",
              "        0.02424056, -0.03245485, -0.00246377, -0.04548598,  0.01208758,\n",
              "       -0.00146036], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM55i5DjH94E"
      },
      "source": [
        "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKaN5gnEH94E"
      },
      "source": [
        "# Create a layer that uses the mask_zero kwarg\n",
        "masking_embedding_layer=tf.keras.layers.Embedding(input_dim=501,output_dim=16,mask_zero=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIC7QX7PH94G",
        "outputId": "87865917-7e67-4194-e0d6-23d007f78b71"
      },
      "source": [
        "# Apply this layer to the sequence and see the _keras_mask property\n",
        "masked_sequence=masking_embedding_layer(sequence)\n",
        "masked_sequence._keras_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=74, shape=(1, 4, 1), dtype=bool, numpy=\n",
              "array([[[False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEWIYD8YH94I"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Embedding Projector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_KaAU1kIMRi",
        "outputId": "05b5cec9-e2cc-41a8-8de5-bfd9a577a24e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urtrTWQ2H94I"
      },
      "source": [
        "#### Load and preprocess the IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IStW5oGH94I"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50bjCHWAH94L"
      },
      "source": [
        "# Load the dataset\n",
        "(x_train,y_train),(x_test,y_test)=get_and_pad_imdb_dataset()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRMfQ0gtH94P"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6wj7MNvH94Q"
      },
      "source": [
        "# Get the word index\n",
        "imdb_word_index=get_imdb_word_index()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPBKx4yrH94S"
      },
      "source": [
        "# Swap the keys and values of the word index\n",
        "inv_imdb_word_index={val:key for key,val in imdb_word_index.items()}\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64e5dj9KH94V",
        "outputId": "0f9f3202-a0ba-40a4-b93d-8f919ff26b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# View the first dataset example sentence\n",
        "[inv_imdb_word_index[index] for index in x_train[0] if index >2]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'film',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'casting',\n",
              " 'location',\n",
              " 'scenery',\n",
              " 'story',\n",
              " 'direction',\n",
              " \"everyone's\",\n",
              " 'really',\n",
              " 'suited',\n",
              " 'the',\n",
              " 'part',\n",
              " 'they',\n",
              " 'played',\n",
              " 'and',\n",
              " 'you',\n",
              " 'could',\n",
              " 'just',\n",
              " 'imagine',\n",
              " 'being',\n",
              " 'there',\n",
              " 'robert',\n",
              " 'is',\n",
              " 'an',\n",
              " 'amazing',\n",
              " 'actor',\n",
              " 'and',\n",
              " 'now',\n",
              " 'the',\n",
              " 'same',\n",
              " 'being',\n",
              " 'director',\n",
              " 'father',\n",
              " 'came',\n",
              " 'from',\n",
              " 'the',\n",
              " 'same',\n",
              " 'scottish',\n",
              " 'island',\n",
              " 'as',\n",
              " 'myself',\n",
              " 'so',\n",
              " 'i',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'real',\n",
              " 'connection',\n",
              " 'with',\n",
              " 'this',\n",
              " 'film',\n",
              " 'the',\n",
              " 'witty',\n",
              " 'remarks',\n",
              " 'throughout',\n",
              " 'the',\n",
              " 'film',\n",
              " 'were',\n",
              " 'great',\n",
              " 'it',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'so',\n",
              " 'much',\n",
              " 'that',\n",
              " 'i',\n",
              " 'bought',\n",
              " 'the',\n",
              " 'film',\n",
              " 'as',\n",
              " 'soon',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'released',\n",
              " 'for',\n",
              " 'and',\n",
              " 'would',\n",
              " 'recommend',\n",
              " 'it',\n",
              " 'to',\n",
              " 'everyone',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'and',\n",
              " 'the',\n",
              " 'fly',\n",
              " 'fishing',\n",
              " 'was',\n",
              " 'amazing',\n",
              " 'really',\n",
              " 'cried',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " 'it',\n",
              " 'was',\n",
              " 'so',\n",
              " 'sad',\n",
              " 'and',\n",
              " 'you',\n",
              " 'know',\n",
              " 'what',\n",
              " 'they',\n",
              " 'say',\n",
              " 'if',\n",
              " 'you',\n",
              " 'cry',\n",
              " 'at',\n",
              " 'a',\n",
              " 'film',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'been',\n",
              " 'good',\n",
              " 'and',\n",
              " 'this',\n",
              " 'definitely',\n",
              " 'was',\n",
              " 'also',\n",
              " 'to',\n",
              " 'the',\n",
              " 'two',\n",
              " 'little',\n",
              " \"boy's\",\n",
              " 'that',\n",
              " 'played',\n",
              " 'the',\n",
              " 'of',\n",
              " 'norman',\n",
              " 'and',\n",
              " 'paul',\n",
              " 'they',\n",
              " 'were',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'children',\n",
              " 'are',\n",
              " 'often',\n",
              " 'left',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'list',\n",
              " 'i',\n",
              " 'think',\n",
              " 'because',\n",
              " 'the',\n",
              " 'stars',\n",
              " 'that',\n",
              " 'play',\n",
              " 'them',\n",
              " 'all',\n",
              " 'grown',\n",
              " 'up',\n",
              " 'are',\n",
              " 'such',\n",
              " 'a',\n",
              " 'big',\n",
              " 'profile',\n",
              " 'for',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'film',\n",
              " 'but',\n",
              " 'these',\n",
              " 'children',\n",
              " 'are',\n",
              " 'amazing',\n",
              " 'and',\n",
              " 'should',\n",
              " 'be',\n",
              " 'praised',\n",
              " 'for',\n",
              " 'what',\n",
              " 'they',\n",
              " 'have',\n",
              " 'done',\n",
              " \"don't\",\n",
              " 'you',\n",
              " 'think',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'story',\n",
              " 'was',\n",
              " 'so',\n",
              " 'lovely',\n",
              " 'because',\n",
              " 'it',\n",
              " 'was',\n",
              " 'true',\n",
              " 'and',\n",
              " 'was',\n",
              " \"someone's\",\n",
              " 'life',\n",
              " 'after',\n",
              " 'all',\n",
              " 'that',\n",
              " 'was',\n",
              " 'shared',\n",
              " 'with',\n",
              " 'us',\n",
              " 'all']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEWW_bGEH94Y"
      },
      "source": [
        "#### Build an Embedding layer into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8ZsWSTrH94Z"
      },
      "source": [
        "# Get the maximum token value\n",
        "\n",
        "max_index_value=max(imdb_word_index.values())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc1ctkHYH94c"
      },
      "source": [
        "# Specify an embedding dimension\n",
        "embedding_dim=16\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yByNCHnH94f"
      },
      "source": [
        "# Build a model using Sequential:\n",
        "#     1. Embedding layer\n",
        "#     2. GlobalAveragePooling1D\n",
        "#     3. Dense\n",
        "model=tf.keras.Sequential([\n",
        "           tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim,mask_zero=False)  ,\n",
        "           tf.keras.layers.GlobalAveragePooling1D(),\n",
        "           tf.keras.layers.Dense(units=1,activation='sigmoid')              \n",
        "\n",
        "]\n",
        ")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ts-QXwKH94h"
      },
      "source": [
        "# Functional API refresher: use the Model to build the same model\n",
        "\n",
        "review_sequence=tf.keras.Input((None,))\n",
        "embedding_sequence=tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim)(review_sequence)\n",
        "average_embedding=tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
        "positive_prob=tf.keras.layers.Dense(1,activation='sigmoid')(average_embedding)\n",
        "model=tf.keras.Model(inputs=review_sequence,outputs=positive_prob)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp0JnxbQH94k",
        "outputId": "2fb8e92b-4688-4472-861b-a87d41756e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZIMFki6H94n"
      },
      "source": [
        "#### Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPddJnO5H94n"
      },
      "source": [
        "# Compile the model with a binary cross-entropy loss\n",
        "model.compile(loss='binary_crossentropy',metrics='accuracy',optimizer='adam')\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDFU38UIH94p",
        "outputId": "7f629d48-35a8-4486-87f0-7a835a52d550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the model using .fit(), savng its history\n",
        "\n",
        "history=model.fit(x_train,y_train,epochs=5,batch_size=32,validation_data=(x_test,y_test),validation_steps=20)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4809 - accuracy: 0.8383 - val_loss: 0.4696 - val_accuracy: 0.8094\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4430 - accuracy: 0.8520 - val_loss: 0.4355 - val_accuracy: 0.8391\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4108 - accuracy: 0.8622 - val_loss: 0.4082 - val_accuracy: 0.8547\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3833 - accuracy: 0.8720 - val_loss: 0.3866 - val_accuracy: 0.8625\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3607 - accuracy: 0.8784 - val_loss: 0.3797 - val_accuracy: 0.8422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3AO11jOH94r",
        "outputId": "a0090237-6f27-4295-ef54-1f9ca3c50e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ikTcWoBH94u"
      },
      "source": [
        "#### The TensorFlow embedding projector\n",
        "\n",
        "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_cYLBIiH94v"
      },
      "source": [
        "# Retrieve the embedding layer's weights from the trained model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_P4_jCoH94w"
      },
      "source": [
        "# Save the word Embeddings to tsv files\n",
        "# Two files: \n",
        "#     one contains the embedding labels (meta.tsv),\n",
        "#     one contains the embeddings (vecs.tsv)\n",
        "\n",
        "import io\n",
        "from os import path\n",
        "\n",
        "out_v = io.open(path.join('data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
        "out_m = io.open(path.join('data', 'meta.tsv'), 'w', encoding='utf-8')\n",
        "\n",
        "k = 0\n",
        "\n",
        "for word, token in word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()\n",
        "# beware large collections of embeddings!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJPQtIZdH944"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Recurrent neural network layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQDxIriRH944"
      },
      "source": [
        "#### Initialize and pass an input to a SimpleRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBJ8a5vzH945"
      },
      "source": [
        "# Create a SimpleRNN layer and test it\n",
        "\n",
        "# input of the form (batch,sequence,features)\n",
        "simplernn_layers=tf.keras.layers.SimpleRNN(units=16)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDl9hK-8H947",
        "outputId": "3a0e6e56-378c-49d9-8e58-76d39bbba53e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Note that only the final cell output is returned\n",
        "sequence=tf.constant([[[1.,1.],[2.,2.],[56.,-100]]])\n",
        "layer_output=simplernn_layers(sequence)\n",
        "layer_output\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "array([[-0.9995051 ,  1.        ,  1.        ,  1.        , -1.        ,\n",
              "        -1.        ,  1.        , -1.        , -1.        ,  1.        ,\n",
              "         1.        , -1.        , -1.        , -0.98492384,  1.        ,\n",
              "        -1.        ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nH0tWhEH95A"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR-uHxhiH95B"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwd0mwJkH95D",
        "outputId": "73fb42df-9497-4dad-c4de-9f109bc768b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the dataset\n",
        "num_words=5000\n",
        "maxlen=300\n",
        "(x_train,y_train),(x_test,y_test)=get_and_pad_imdb_dataset(num_words=num_words,maxlen=300)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPANcwE1H95H"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=5000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvuhek9BH95J",
        "outputId": "4619d069-5a6f-4609-b14d-0a03705bdd3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "imdb_word_index=get_imdb_word_index(num_words=num_words)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aav965QDH95L"
      },
      "source": [
        "#### Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ltGa8pH95L"
      },
      "source": [
        "# Get the maximum index value\n",
        "\n",
        "max_index_value=max(imdb_word_index.values())\n",
        "embedding_dim=128"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FHM89-4H95O"
      },
      "source": [
        "# Using Sequential, build the model:\n",
        "# 1. Embedding.\n",
        "# 2. LSTM.\n",
        "# 3. Dense.\n",
        "model=tf.keras.Sequential([\n",
        "     tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim,mask_zero=True),\n",
        "     tf.keras.layers.LSTM(units=60),\n",
        "     tf.keras.layers.Dense(units=1,activation='sigmoid')                \n",
        "])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWPRGm6sH95R"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zotvkXSfH95R"
      },
      "source": [
        "# Compile the model with binary cross-entropy loss\n",
        "\n",
        "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgUS_2WIH95T",
        "outputId": "a39b35cf-8b95-420d-d492-36983759ad25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit the model and save its training history\n",
        "history=model.fit(x_train,y_train,epochs=3,batch_size=500,validation_data=(x_test,y_test))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "39/39 [==============================] - 28s 713ms/step - loss: 0.1234 - accuracy: 0.9565 - val_loss: 0.3256 - val_accuracy: 0.8778\n",
            "Epoch 2/3\n",
            "39/39 [==============================] - 27s 697ms/step - loss: 0.1105 - accuracy: 0.9615 - val_loss: 0.3419 - val_accuracy: 0.8792\n",
            "Epoch 3/3\n",
            "39/39 [==============================] - 28s 712ms/step - loss: 0.1010 - accuracy: 0.9656 - val_loss: 0.3521 - val_accuracy: 0.8798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpiwIFlfOo0b",
        "outputId": "31d463c6-73ee-425f-fba0-6db06b2a20c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "608/608 [==============================] - 29s 48ms/step - loss: 0.3325 - accuracy: 0.8781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33247852325439453, 0.8781490921974182]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNMVsBFsH95V"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faKUwy8DH95V",
        "outputId": "3c0340de-3891-444a-c9b8-636fefcce501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-14f5d334cc79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0macc\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mval_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mloss\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blC-Bzv4H95Y"
      },
      "source": [
        "#### Make predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT0y-viOH95Y",
        "outputId": "b63e3480-df00-46f4-ac46-c128585c0b92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# View the first test data example sentence\n",
        "# (invert the word index)\n",
        "inv_imdb_word_index={val:key for key,val in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_test[0] if index >2]\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['please',\n",
              " 'give',\n",
              " 'this',\n",
              " 'one',\n",
              " 'a',\n",
              " 'miss',\n",
              " 'br',\n",
              " 'br',\n",
              " 'and',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'cast',\n",
              " 'rendered',\n",
              " 'terrible',\n",
              " 'performances',\n",
              " 'the',\n",
              " 'show',\n",
              " 'is',\n",
              " 'flat',\n",
              " 'flat',\n",
              " 'flat',\n",
              " 'br',\n",
              " 'br',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " 'how',\n",
              " 'michael',\n",
              " 'madison',\n",
              " 'could',\n",
              " 'have',\n",
              " 'allowed',\n",
              " 'this',\n",
              " 'one',\n",
              " 'on',\n",
              " 'his',\n",
              " 'plate',\n",
              " 'he',\n",
              " 'almost',\n",
              " 'seemed',\n",
              " 'to',\n",
              " 'know',\n",
              " 'this',\n",
              " \"wasn't\",\n",
              " 'going',\n",
              " 'to',\n",
              " 'work',\n",
              " 'out',\n",
              " 'and',\n",
              " 'his',\n",
              " 'performance',\n",
              " 'was',\n",
              " 'quite',\n",
              " 'so',\n",
              " 'all',\n",
              " 'you',\n",
              " 'madison',\n",
              " 'fans',\n",
              " 'give',\n",
              " 'this',\n",
              " 'a',\n",
              " 'miss']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqhocrzVH95a",
        "outputId": "776e3e76-9646-421b-e4f1-8ecc255cbafd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get the model prediction using model.predict()\n",
        "\n",
        "model.predict(x_test[None,0,:])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.10913296]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5n2s8TPH95b",
        "outputId": "d5d25793-7094-46cb-8cdd-6d545c795727",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get the corresponding label\n",
        "y_test[0]\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kelDHTwH95d"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_6\"></a>\n",
        "## Stacked RNNs and the Bidirectional wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9hOLaF0H95d"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlhC0kNeH95d"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FA1lEYgH95f"
      },
      "source": [
        "# Load the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_rgVNe8H95h"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1BEiLjhH95k"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71zZ2hxMH95l"
      },
      "source": [
        "#### Build stacked and bidirectional recurrent models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61evA537H95m"
      },
      "source": [
        "# Get the maximum index value and specify an embedding dimension\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6zDPq1nH95o"
      },
      "source": [
        "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uxWnYT9H95q"
      },
      "source": [
        "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exo2n5vgH95r"
      },
      "source": [
        "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ8Bv801H95s"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3CpQN3pH95t"
      },
      "source": [
        "# Compile the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiuQLrCrH95u"
      },
      "source": [
        "# Train the model, saving its history\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeRESIxuH95v"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}