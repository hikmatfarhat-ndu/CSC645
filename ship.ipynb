{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600677363809",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<a href=\"https://colab.research.google.com/github/hikmatfarhat-ndu/CSC645/blob/master/kernas-cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(img_train,label_train),(img_test,label_test)=tf.keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(50000,)\n"
    }
   ],
   "source": [
    "img_train=img_train.reshape(50000,32*32*3)/255.\n",
    "img_test=img_test.reshape(10000,32*32*3)/255.\n",
    "label_train=label_train.reshape(50000)\n",
    "label_test=label_test.reshape(10000)\n",
    "img_train=img_train.T\n",
    "img_test=img_test.T\n",
    "\n",
    "#print(img_train.shape)\n",
    "print(label_train.shape)\n",
    "#print(label_train[0])\n",
    "#print(one_hot[0])\n",
    "\n"
   ]
  },
  {
   "source": [
    "There are ten types of images labeled from 0 to 9 where 8 is for ships. Since we are doing binary classification, i.e. ship or not ship we convert anything that is 8 to 1 and everything else to 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature=8\n",
    "for i in range(label_train.shape[0]):\n",
    "    if label_train[i]==feature:\n",
    "        label_train[i]=1\n",
    "    else:\n",
    "        label_train[i]=0\n",
    "\n",
    "for i in range(label_test.shape[0]):\n",
    "    if label_test[i]==feature:\n",
    "        label_test[i]=1\n",
    "    else:\n",
    "        label_test[i]=0        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \n",
    "#w is a column vector. later on we take the transpose before operating on w\n",
    "    w = np.zeros((1,dim))\n",
    "    b = 0\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "# m is the number of samples which is the number of columns in X\n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w,X)+b)   # compute activation\n",
    "    cost=-np.sum(Y*np.log(A)+(1-Y)*np.log(1-A))/m\n",
    "    # Compute Derivatives\n",
    "\n",
    "    dw = np.dot(X,(A-Y).T)/m\n",
    "\n",
    "    db = np.sum(A-Y)/m\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "#    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    \n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(w, b, X, Y, num_iterations,learning_rate, print_cost = False):\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Cost and gradient calculation \n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        # update rule\n",
    "        w = w-learning_rate*dw.T\n",
    "        b = b-learning_rate*db\n",
    "\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params,grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    \n",
    "    # Compute vector \"A\" predicting\n",
    "    #    the probabilities of a ship being present in the picture\n",
    "\n",
    "    A = sigmoid(np.dot(w,X)+b)\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A[0,i]>=0.5:\n",
    "            Y_prediction[0,i]=1\n",
    "        else:\n",
    "            Y_prediction[0,i]=0\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "\n",
    "    return Y_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cost after iteration 0: 0.693147\nCost after iteration 100: 0.278183\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-3b685f86a592>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-ba585e77dc0b>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(w, b, X, Y, num_iterations, learning_rate, print_cost)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# Cost and gradient calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;31m# Retrieve derivatives from grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mdw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dw'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-414f1d0f86bb>\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(w, b, X, Y)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Compute Derivatives\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_iterations = 5000\n",
    "learning_rate = 0.026\n",
    "print_cost = True\n",
    "\n",
    "    \n",
    "# initialize parameters with zeros \n",
    "w, b = initialize_with_zeros(img_train.shape[0])\n",
    "\n",
    "# Gradient descent \n",
    "parameters, grads= learn(w, b, img_train, label_train, num_iterations, learning_rate, print_cost)\n",
    "\n",
    "\n",
    "# Retrieve parameters w and b from dictionary \"parameters\"\n",
    "w = parameters[\"w\"]\n",
    "b = parameters[\"b\"]\n",
    "\n",
    "# Predict test/train set examples\n",
    "Y_prediction_test = predict(w, b, X_test)\n",
    "Y_prediction_train = predict(w, b, X)\n",
    "\n",
    "# Print train/test Errors\n",
    "\n",
    "\n",
    "print(\"train accuracy:\"+str((100 - np.mean(np.abs(Y_prediction_train - Y)) * 100)))\n",
    "print(\"test accuracy:\"+str((100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}